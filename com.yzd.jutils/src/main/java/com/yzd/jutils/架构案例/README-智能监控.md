- 智能监控
    - [宜信智能监控平台建设实践|分享实录](https://my.oschina.net/u/4007037/blog/3131616)
- 技术比较Agent和Agentless监控优缺点
    - [技术比较Agent和Agentless监控优缺点](https://www.cnblogs.com/wlzjdm/p/4711053.html)
- []()
- []()

## AIOps ->特别推荐参考
- 监控系统分为以下几部分
```
监控：
open falcon： 用于监控主机和网络。
Prometheus： 应用类的监控信息接入到了Prometheus，比如jvm，线程，内存，cpu，TCP 连接数。
APM： 属于业务层的链路监控信息，包括了mysql的调用，java的rpc调用，堆栈及jvm情况。
数据监控大盘： 监控数据库的数据binlog的状态变化，与通过hot-winter预测的结果进行比对，然后对外进行告警。
cat监控，业务集成cat进行埋点，来监控
elk日志监控： 统一日志平台

告警：
ESAlert： ES告警
Grafana告警：  grafana的告警
lens告警：自研的智能告警平台
Cat告警： 基于规则告警。
业务自身的抛出告警事件。例如支付业务组，将异常跑到redis，运维消费时间后发送到告警通道
告警通道支持短信，邮件，电话，企业微信，钉钉等
```
- 监控体系
> 监控体系大体分为三类，安全监控，稳定性监控，业务监控，我们本次讨论的主要是稳定性监控和部分业务监控

```
1.安全监控：
客户端安全，系统安全，网络安全，服务器安全，应用安全，业务逻辑安全，关注攻击事件，泄露事件 
稳定性监控：
2.基础监控：网络拓扑监控，外网（CDN，DNS，BGP），内网（waf，防火墙，交换机，主机，容器网络）， 系统监控（cpu，内存，磁盘，负载）
PaaS中间件监控： 数据库，rabbitmq，redis，es，lvs等基础组件监控。
应用监控：流量，延迟，错误率，负载，全链路追踪，jvm，连接数
部分业务监控： 下单数，支付成功数等核心业务链路指标
IaaS， PaaS， 应用，业务，各层之间又有相互关联。
3.业务监控：
运营类，比如因为运力问题导致自营外卖拒单，不属于程序和系统的问题，属于业务运营的问题的监控
目前我们的监控体系各自为战，需要相互打通，从业务的角度，聚焦业务，提升业务稳定性为主，各层以google sre的黄金指标为指导原则来构建新型的监控体系：
关注用户体验
关注业务核心指标
强调SLA，MTTR
深入业务链路拓扑
提高运维的人效
善用数据，挖掘数据
举例来讲：
ingress的debug模式，导致全系统慢的问题。首先我们缺失了对ingress的监控，我们应该关注ingress的什么指标呢？
延迟： 自身延迟，和下游延迟。 类似于nginx的upstream time和request time，二者想减就是自身消耗的时间，TP95.Tp99的变化
流量： 对于不同维度的域名，不同地域的后端的流量变化，监控。
错误率： 出现超时，非正常的错误率的变化
饱和度：系统的cpu，负载情况。
恰恰是我们缺失了关键的耗时，导致故障发生时候，其模块变成了黑盒，不具备可观测性。
我们需要补全我们各层的监控，并让监控串联起来。
各地的网络=>CDN=>IDC(bgp)=>核心交换机=》外出接入网关=》内层网关=》应用网关=》应用=》中间件=》数据库=》到上层的业务监控，梳理每层的监控，必须具备google   sre监控的4个黄金指标。  
```
- 根因无法快速定位
```
有了各层的系统监控，但是缺少各层之间的连接关系，无法做到故障传播链路绘制出来，无法全视角的定位问题，只能依靠具备全局思考的系统工程师的经验。但是随着系统的复杂化，个人是很难全面的跟着系统变化的，我们需要系统的建设故障传播路径。
CMDB和元数据系统要发挥作用，建立东西向的应用拓扑关系（APM承担），即应用与应用间关系、服务与服务间关系；建立南北向的资源依赖关系，即服务依赖哪些机器；建立交易链；建立监控KPI与应用、服务、资源的关系。借助这些关系，分析故障传播链，进行根源分析。
实现此目标，我们需要构建几个系统来：
网络拓扑图： 机房网络的拓扑构造自动生成，自动绘制或者自动补充。避免人为维护的疏忽。 
元数据系统： 包括偏静态的部分从CMDB得到机器，机架及IDC的配置信息，动态部分（容器与物理机的对应关系，IP及端口），环境及服务树
APM集成OpenTracing： 目前APM不支持opentracing协议，对于后面要实施的service mesh和node，Nginx的集成都有些问题，希望APM能够完成端到端的链路传递。
我们需要覆盖全链路的立体监控，还要打通监控的南北向和东西向关联关系，对故障能够快速定位。当发生问题的时候，能有响应的预案进行处理。
```
- 自动化及风险预案不足
```
基础方向的重点方向是：
统一的网关平台： 网关是整个流量的出入口，灵活的定制了熔断，限流，审计及流量调度。
mesh的解决方案： 服务网格化的统一解决方案，非侵入性的，系统解决限流，熔断，流量调度的问题
全链路的压测： 测试团队及测试开发团队的系统化建设较弱，全链路压测一直开展的不是很系统，我们需要链路压测，对系统的监控，熔断，限流做检测
```
- 构建AIOps的数据体系
```
数据中台体系的时候，讲过建设数据中台的四个字"采，存，通，用", 既然AIOps要有AI，就需要有数据，建设运维的数据体系的方法论，试着从数据中台的建设步骤出发。
采，我们目前有了各种数据源，日志源，openfalcon的基础监控数据，APM的数据源，数据库，redis，es，zk中间件及存储的监控数据源，以及基于数据库binlog的业务数据，k8s的元数据
存，时序数据，日志数据，及业务数据，需要考虑合适的存储，包括离线存储，和实时存储。
通，对于根因分析，我们需要关联各种数据，将业务，应用，中间件，物理机，网络等贯通使用。
用，构建以业务核心指标的监控告警体系，支持业务异常指标的下钻分析，及基于规则和算法的根因分析，故障止损或者恢复的智能决策。
使用场景： 核心支付链路关注的是支付成功率（成功率），支付成功数量（流量）， 支付的Tp99耗时（延迟），峰值到达压测的百分之多少（饱和度）。 以上几个指标还要区分维度， 维度分为服务区
```


### 名词解释
- [性能测试：一种计算 TP90、TP95 和 TP99 等水位线的方法](https://blog.csdn.net/qq_35246620/article/details/101284451)
```
先解释一下 TP90、TP95 和 TP99 的含义：
TP90，top percent 90，即 90% 的数据都满足某一条件；
TP95，top percent 95，即 95% 的数据都满足某一条件；
TP99，top percent 99，即 99% 的数据都满足某一条件；

```